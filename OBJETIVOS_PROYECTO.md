# Objetivos del Proyecto Final - Vehicle Energy Dataset

## Estructura General del Proyecto

### Objetivo Principal
Modelar el consumo energ√©tico de veh√≠culos (combusti√≥n, h√≠bridos y el√©ctricos) a partir de variables de conducci√≥n, caracter√≠sticas del veh√≠culo y condiciones ambientales utilizando t√©cnicas de Machine Learning y Deep Learning.

---

## FASE 1: Exploraci√≥n y An√°lisis Inicial de Datos

### 1.1 Carga y Comprensi√≥n del Dataset
- [x] Descargar y cargar el Vehicle Energy Dataset (VED)
- [ ] Identificar y documentar la estructura de datos est√°ticos vs din√°micos
- [ ] Analizar dimensiones del dataset (n√∫mero de registros, veh√≠culos, viajes)
- [ ] Documentar diccionario de variables con descripci√≥n de cada feature
- [ ] Identificar tipos de datos (num√©ricos, categ√≥ricos, temporales)

### 1.2 An√°lisis Exploratorio de Datos (EDA) - Estad√≠sticas B√°sicas
- [ ] Calcular estad√≠sticas descriptivas (media, mediana, desviaci√≥n est√°ndar, min, max)
- [ ] Analizar distribuci√≥n de variables continuas con histogramas y boxplots
- [ ] Examinar balance de clases en variables categ√≥ricas (tipo de veh√≠culo, tipo de ruta)
- [ ] Identificar rangos razonables para cada variable

### 1.3 EDA - An√°lisis de Valores Faltantes y Calidad de Datos
- [ ] Generar mapa de calor de valores faltantes por variable
- [ ] Calcular porcentaje de missingness por columna y por veh√≠culo
- [ ] Identificar patrones en datos faltantes (MCAR, MAR, MNAR)
- [ ] Documentar variables con >50% de missingness (candidatas a eliminar)

### 1.4 EDA - An√°lisis de Valores At√≠picos
- [ ] Detectar outliers usando m√©todo IQR y Z-score
- [ ] Visualizar outliers con boxplots por variable y tipo de veh√≠culo
- [ ] Analizar si outliers son errores de medici√≥n o eventos reales
- [ ] Documentar decisiones sobre tratamiento de outliers

### 1.5 EDA - An√°lisis de Distribuciones por Tipo de Veh√≠culo
- [ ] Comparar distribuci√≥n de consumo entre el√©ctricos, h√≠bridos y combusti√≥n
- [ ] Analizar patrones de velocidad por tipo de veh√≠culo
- [ ] Visualizar diferencias en aceleraci√≥n y desaceleraci√≥n
- [ ] Examinar uso de potencia auxiliar (AC, calefacci√≥n) por tipo

### 1.6 EDA - An√°lisis de Correlaciones
- [ ] Generar matriz de correlaci√≥n entre variables num√©ricas
- [ ] Visualizar heatmap de correlaciones con valores significativos
- [ ] Identificar multicolinealidad entre features (VIF > 10)
- [ ] Analizar correlaci√≥n de cada feature con variable target
- [ ] Documentar features redundantes candidatas a eliminar

### 1.7 EDA - An√°lisis Temporal y de Trayectorias
- [ ] Analizar duraci√≥n promedio de viajes por tipo de veh√≠culo
- [ ] Visualizar 5-10 trayectorias ejemplo (velocidad vs tiempo)
- [ ] Identificar patrones de conducci√≥n (agresiva vs conservadora)
- [ ] Analizar estacionalidad en consumo por temperatura ambiente

### 1.8 EDA - An√°lisis Geogr√°fico y de Rutas
- [ ] Clasificar trayectos por tipo (urbano, suburbano, autopista)
- [ ] Analizar consumo promedio por tipo de ruta
- [ ] Visualizar distribuci√≥n geogr√°fica de trayectos (si hay coordenadas GPS)
- [ ] Identificar rutas m√°s eficientes energ√©ticamente

---

## FASE 2: Limpieza y Curaci√≥n de Datos

### 2.1 Tratamiento de Valores Faltantes
- [ ] Implementar estrategia para variables con <5% missingness (imputaci√≥n)
- [ ] Eliminar variables con >70% de valores faltantes
- [ ] Aplicar imputaci√≥n por mediana/media para variables num√©ricas
- [ ] Aplicar imputaci√≥n por moda para variables categ√≥ricas
- [ ] Considerar imputaci√≥n por KNN o modelo predictivo para casos complejos
- [ ] Documentar todas las decisiones de imputaci√≥n

### 2.2 Tratamiento de Outliers
- [ ] Aplicar winsorization (clip a percentiles 1-99) para variables sensibles
- [ ] Eliminar registros con valores f√≠sicamente imposibles
- [ ] Mantener outliers v√°lidos (ej: consumo alto en aceleraciones bruscas)
- [ ] Documentar impacto de remoci√≥n de outliers en distribuciones

### 2.3 Limpieza de Datos Inconsistentes
- [ ] Verificar rangos v√°lidos (velocidad ‚â• 0, temperatura en rango razonable)
- [ ] Corregir unidades inconsistentes si existen
- [ ] Eliminar registros duplicados
- [ ] Validar coherencia temporal (timestamps ordenados)

### 2.4 Normalizaci√≥n y Estandarizaci√≥n
- [ ] Aplicar StandardScaler a variables con distribuci√≥n normal
- [ ] Aplicar MinMaxScaler a variables con rango fijo conocido
- [ ] Aplicar RobustScaler a variables con outliers persistentes
- [ ] Guardar scalers para uso en producci√≥n

### 2.5 Codificaci√≥n de Variables Categ√≥ricas
- [ ] One-Hot Encoding para variables con <10 categor√≠as (tipo de ruta)
- [ ] Label Encoding para variables ordinales si existen
- [ ] Target Encoding para variables de alta cardinalidad si aplica
- [ ] Documentar mapeos de codificaci√≥n

---

## FASE 3: Feature Engineering

### 3.1 Definici√≥n de Variable Target
- [ ] Calcular consumo energ√©tico por trayecto (kWh/km o L/100km)
- [ ] Crear variable target continua para regresi√≥n
- [ ] Crear variable target categ√≥rica para clasificaci√≥n (Alta/Media/Baja eficiencia)
- [ ] Definir umbrales para categorizaci√≥n basados en percentiles (33%, 66%)
- [ ] Analizar distribuci√≥n de variable target y balance de clases

### 3.2 Agregaci√≥n de Datos Temporales a Nivel Trayecto
- [ ] Agrupar datos por `trip_id` para crear features agregadas
- [ ] Calcular velocidad promedio, m√°xima y m√≠nima por trayecto
- [ ] Calcular aceleraci√≥n promedio, m√°xima y varianza por trayecto
- [ ] Calcular distancia total del trayecto
- [ ] Calcular duraci√≥n total del trayecto
- [ ] Calcular temperatura promedio durante el trayecto

### 3.3 Features Derivadas - Comportamiento de Conducci√≥n
- [ ] Crear ratio velocidad/aceleraci√≥n promedio
- [ ] Calcular porcentaje de tiempo en aceleraci√≥n vs desaceleraci√≥n
- [ ] Crear indicador de conducci√≥n agresiva (aceleraciones bruscas)
- [ ] Calcular n√∫mero de paradas completas (velocidad = 0)
- [ ] Crear feature de "suavidad de conducci√≥n" (varianza de velocidad)
- [ ] Calcular tiempo en diferentes rangos de velocidad (0-30, 30-60, 60+ km/h)

### 3.9 Features en el Dominio de la Frecuencia (An√°lisis de Fourier)
- [ ] Justificaci√≥n: muchas se√±ales din√°micas (velocidad, aceleraci√≥n, consumo instant√°neo) contienen componentes peri√≥dicos o arm√≥nicos relacionados con patrones de conducci√≥n (ciclos de aceleraci√≥n/frenado, comportamiento en autopista vs urbano); el an√°lisis espectral permite extraer informaci√≥n complementaria o alternativa a las agregaciones temporales.
- [ ] Extracci√≥n b√°sica por trayecto (`trip_id`): calcular FFT/PSD de series temporales (ej. velocidad, aceleraci√≥n, fuel_rate, ac_power)
- [ ] Features sugeridas a extraer por serie y por trayecto:
  - Dominant frequency (Hz) y su amplitud
  - Top-K peaks (frecuencias y amplitudes)
  - Total spectral power (band power) en bandas definidas (baja frecuencia, media, alta)
  - Spectral centroid (centro de masa del espectro)
  - Spectral entropy (medida de dispersi√≥n de potencia espectral)
  - Ratio de potencia entre bandas (ej. BF/MF/HF)
  - Energy of harmonics (par/√≠mpar) y relaci√≥n se√±al/ruido espectral
- [ ] Procedimiento:
  - Re-muestrear la serie a frecuencia uniforme (p. ej. 1 Hz) si fuese necesario
  - Aplicar ventana (Hann) y calcular PSD con Welch o FFT con zero-padding
  - Extraer features num√©ricos y guardarlos a nivel `trip_id`
  - Normalizar/estandarizar features espectrales antes de entrenar modelos
- [ ] Usos:
  - Complementar features temporales tradicionales en modelos supervisados
  - Reemplazar algunas agregaciones si la representaci√≥n espectral resulta m√°s informativa
  - Detecci√≥n de anomal√≠as usando reconstrucci√≥n en dominio espectral o thresholds de bandpower
- [ ] Guardar funciones reutilizables en `src/fourier_features.py` y ejemplos en `notebooks/08_Fourier_Analysis.ipynb`


### 3.4 Features Derivadas - Energ√≠a y Eficiencia
- [ ] Calcular energ√≠a cin√©tica promedio (0.5 * m * v¬≤)
- [ ] Crear ratio potencia auxiliar / consumo total
- [ ] Calcular eficiencia regenerativa para veh√≠culos el√©ctricos/h√≠bridos
- [ ] Para h√≠bridos: crear ratio uso motor el√©ctrico vs combusti√≥n
- [ ] Para el√©ctricos: crear features de estado de bater√≠a (SOC promedio, variaci√≥n)

### 3.5 Features Derivadas - Condiciones Ambientales
- [ ] Binning de temperatura en rangos (fr√≠o <10¬∞C, templado 10-25¬∞C, calor >25¬∞C)
- [ ] Crear indicador de uso de AC/calefacci√≥n basado en temperatura
- [ ] Calcular variaci√≥n de temperatura durante el trayecto

### 3.6 Features Derivadas - Caracter√≠sticas de Ruta
- [ ] Crear ratio distancia/duraci√≥n (velocidad efectiva)
- [ ] Calcular tortuosidad de ruta (cambios de direcci√≥n) si hay datos GPS
- [ ] Crear indicador de ruta urbana vs autopista basado en velocidad
- [ ] Calcular elevaci√≥n ganada/perdida si hay datos de altitud

### 3.7 Features de Interacci√≥n
- [ ] Interacci√≥n tipo_vehiculo √ó velocidad_promedio
- [ ] Interacci√≥n temperatura √ó potencia_auxiliar
- [ ] Interacci√≥n tipo_ruta √ó aceleracion_promedio
- [ ] Interacci√≥n peso_vehiculo √ó aceleracion_promedio

### 3.8 Selecci√≥n de Features
- [ ] Aplicar an√°lisis de importancia con Random Forest inicial
- [ ] Aplicar Recursive Feature Elimination (RFE)
- [ ] Calcular Variance Inflation Factor (VIF) para eliminar multicolinealidad
- [ ] Seleccionar top 15-25 features m√°s relevantes
- [ ] Documentar justificaci√≥n de features seleccionadas

---

## FASE 4: Preparaci√≥n de Datasets

### 4.1 Estrategia de Muestreo para Desarrollo
- [ ] Crear dataset de desarrollo con 5,000-10,000 muestras
- [ ] Asegurar representatividad por tipo de veh√≠culo en muestra
- [ ] Asegurar representatividad por tipo de ruta en muestra
- [ ] Aplicar stratified sampling basado en variable target
- [ ] Guardar √≠ndices de muestras seleccionadas

### 4.2 Divisi√≥n Train-Validation-Test (Desarrollo)
- [ ] Separar 20% como test set (reservado hasta evaluaci√≥n final)
- [ ] Del 80% restante (dev set), dividir en:
  - [ ] 80% train (64% del total)
  - [ ] 20% validation (16% del total)
- [ ] Aplicar stratified split para mantener distribuciones
- [ ] Verificar que veh√≠culos no se repitan entre conjuntos (data leakage)
- [ ] Guardar splits en archivos separados

### 4.3 Dataset Completo para Evaluaci√≥n Final
- [ ] Definir tama√±o de dataset completo (50,000-100,000+ muestras)
- [ ] Aplicar misma estrategia de split al dataset completo
- [ ] Reservar test set final sin tocar hasta √∫ltima fase
- [ ] Documentar tama√±os finales de cada conjunto

---

## FASE 5: Modelado - Enfoque Supervisado (alineado con I302)

Esta fase se centra en los modelos y conceptos vistos en el programa I302: regresi√≥n lineal y regularizada, regresi√≥n no lineal y no param√©trica, clasificaci√≥n discriminativa y generativa, m√°quinas de soporte vectorial, vecinos m√°s cercanos, √°rboles y ensembles.

### 5.0 Baseline y Diagn√≥stico
- [ ] Implementar predictor dummy (media) y predictor por grupo (media por tipo de veh√≠culo)
- [ ] Calcular m√©tricas baseline: RMSE, MAE, R¬≤, MAPE y usar como referencia m√≠nima
- [ ] Analizar bias-variance del baseline y establecer umbrales m√≠nimos de mejora

### 5.1 Regresi√≥n (temas vistos)
- [ ] Regresi√≥n Lineal ordinaria (OLS) ‚Äî derivaci√≥n y evaluaci√≥n
- [ ] Regresi√≥n regularizada: Ridge (L2), Lasso (L1) ‚Äî interpretaci√≥n Bayesiana / MAP
- [ ] Polinomios y regresi√≥n no lineal (features polin√≥micas)
- [ ] Modelos no-param√©tricos para regresi√≥n: KNN regressor, kernel regression (si aplica)
- [ ] Validaci√≥n: k-fold Cross-Validation, curvas de validaci√≥n (learning curves), diagn√≥stico de over/underfitting
- [ ] M√©tricas: RMSE, MAE, R¬≤, MAPE; an√°lisis de residuos y homocedasticidad

### 5.2 Clasificaci√≥n (si se elige este enfoque)
- [ ] Regresi√≥n log√≠stica (binaria y multiclase con one-vs-rest / softmax)
- [ ] Modelos generativos: GDA / LDA, Naive Bayes ‚Äî revisi√≥n te√≥rica y aplicaci√≥n
- [ ] KNN para clasificaci√≥n y tratamiento de desbalance (stratified sampling, reweighting)
- [ ] SVM para clasificaci√≥n (margen, kernels, regularizaci√≥n)
- [ ] M√©tricas: accuracy, precision, recall, F1, ROC-AUC, matriz de confusi√≥n

### 5.3 √Årboles y Ensembles (visto en curso)
- [ ] √Årboles de decisi√≥n para regresi√≥n y clasificaci√≥n ‚Äî interpretaci√≥n y poda
- [ ] Random Forest: bagging, OOB error, feature importance
- [ ] Boosting y Gradient Boosting (intuici√≥n, regularizaci√≥n): XGBoost/LightGBM como implementaciones pr√°cticas
- [ ] Stacking b√°sico (cuando sea relevante)

### 5.4 Evaluaci√≥n y Buenas Pr√°cticas
- [ ] Fijar semillas y evitar data leakage (mismos veh√≠culos entre splits)
- [ ] Usar validaci√≥n estratificada cuando aplica (por clase o por percentiles del target)
- [ ] Curvas ROC/PR, an√°lisis por subgrupos (tipo veh. / tipo ruta)
- [ ] Interpretar resultados desde la perspectiva de bias-variance y del dominio f√≠sico

---

## FASE 6: Modelado - Aprendizaje Profundo (alineado con I302)

La secci√≥n de Aprendizaje Profundo se centrar√° en MLPs y autoencoders, utilizando los conceptos te√≥ricos vistos en clase (backpropagation, SGD, regularizaci√≥n, normalizaci√≥n y double descent).

### 6.1 Perceptr√≥n multicapa (MLP) para regresi√≥n y clasificaci√≥n
- [ ] Dise√±ar MLPs adecuados para regresi√≥n: arquitecturas simples (ej. 2-4 capas denses)
- [ ] Normalizaci√≥n de inputs (batch normalization / standardization) y su efecto en el entrenamiento
- [ ] Regularizaci√≥n: weight decay (L2), dropout, early stopping
- [ ] Optimizaci√≥n: SGD con momentum, Adam; tuning de learning rate; scheduling
- [ ] Monitoreo: curvas de entrenamiento/validaci√≥n, detecci√≥n de overfitting y double descent
- [ ] Evaluaci√≥n: usar MSE/MAE para regresi√≥n, cross-entropy y m√©tricas de clasificaci√≥n si aplica

### 6.2 Autoencoders y VAE (reducci√≥n de dimensionalidad y detecci√≥n de anomal√≠as)
- [ ] Autoencoder determinista para reducci√≥n dimensional y extracci√≥n de features
- [ ] Variational Autoencoder (VAE): reparameterization trick y loss = reconstruction + KL
- [ ] Uso de representaciones latentes como inputs para modelos supervisados (pipeline AE ‚Üí regresi√≥n)
- [ ] Uso del reconstruction error para detecci√≥n de anomal√≠as (thresholding)

### 6.3 Buenas pr√°cticas de entrenamiento
- [ ] Fijar seed, usar batch size apropiado y normalizar features antes de entrenar
- [ ] Early stopping con patience y checkpoints de modelo
- [ ] Registrar experimentos (tensorboard/MLflow/CSV) para reproducibilidad

### 6.4 √Åmbitos que no son foco del PF
- [ ] GANs y arquitecturas muy avanzadas quedan fuera salvo que el alumno demuestre motivaci√≥n y tiempo adicional

---

## FASE 7: Definici√≥n de Loss Functions y M√©tricas

### 7.1 Loss Functions para Entrenamiento

#### Para Regresi√≥n:
- [ ] **MSE (Mean Squared Error)**: Loss principal para NN
- [ ] **MAE (Mean Absolute Error)**: Loss alternativo m√°s robusto a outliers
- [ ] **Huber Loss**: Combina MSE y MAE, robusto a outliers
- [ ] **MAPE Loss**: Para penalizar errores relativos

#### Para Autoencoders:
- [ ] **Reconstruction MSE**: Para AE est√°ndar
- [ ] **VAE Loss**: Reconstruction + Œ≤√óKL_divergence
- [ ] Experimentar con diferentes valores de Œ≤ (0.5, 1.0, 2.0)

### 7.2 M√©tricas de Evaluaci√≥n para Regresi√≥n
- [ ] **RMSE (Root Mean Squared Error)**: M√©trica principal
- [ ] **MAE (Mean Absolute Error)**: Interpretable en unidades originales
- [ ] **R¬≤ Score**: Proporci√≥n de varianza explicada
- [ ] **MAPE (Mean Absolute Percentage Error)**: Error porcentual
- [ ] **Max Error**: Peor predicci√≥n del modelo
- [ ] Calcular m√©tricas en train, validation y test

### 7.3 M√©tricas de Evaluaci√≥n para Clasificaci√≥n (si aplica)
- [ ] **Accuracy**: Proporci√≥n de predicciones correctas
- [ ] **Precision, Recall, F1-Score**: Por clase
- [ ] **Confusion Matrix**: Visualizaci√≥n de errores
- [ ] **ROC-AUC**: Curva ROC multi-clase

### 7.4 M√©tricas Espec√≠ficas del Dominio
- [ ] Error absoluto en L/100km o kWh/km
- [ ] Porcentaje de predicciones dentro de ¬±10% del valor real
- [ ] Error promedio por tipo de veh√≠culo
- [ ] Error promedio por tipo de ruta

---

## FASE 8: Comparaci√≥n de Modelos

### 8.1 Tabla Comparativa de Performance
- [ ] Crear tabla con RMSE, MAE, R¬≤ para todos los modelos
- [ ] Incluir tiempo de entrenamiento de cada modelo
- [ ] Incluir tiempo de inferencia (predicci√≥n)
- [ ] Destacar mejor modelo por m√©trica

### 8.2 An√°lisis Cualitativo de Predicciones
- [ ] Graficar predicciones vs valores reales (scatter) por modelo
- [ ] Analizar en qu√© rangos de consumo cada modelo falla m√°s
- [ ] Identificar patrones en errores (¬øsubestima o sobreestima?)
- [ ] Comparar distribuci√≥n de errores entre modelos (boxplot)

### 8.3 Comparaci√≥n AE vs VAE vs Features Originales
- [ ] Tabla comparativa de performance downstream con cada representaci√≥n
- [ ] Visualizar espacio latente de AE vs VAE (t-SNE o PCA)
- [ ] Analizar interpretabilidad de features latentes
- [ ] Evaluar si la reducci√≥n de dimensionalidad ayuda o perjudica

### 8.4 An√°lisis de Complejidad vs Performance
- [ ] Graficar trade-off entre complejidad (# par√°metros) y performance
- [ ] Evaluar si modelos m√°s complejos justifican ganancia marginal
- [ ] Considerar trade-off interpretabilidad vs precisi√≥n

---

## FASE 9: Visualizaciones y Gr√°ficos para el Informe

### 9.1 Gr√°ficos de An√°lisis Exploratorio
- [ ] **Histogramas**: Distribuci√≥n de consumo por tipo de veh√≠culo
- [ ] **Boxplots**: Consumo por tipo de ruta y tipo de veh√≠culo
- [ ] **Heatmap**: Matriz de correlaci√≥n entre features principales
- [ ] **Scatter matrix**: Relaciones entre top 4-5 features y target
- [ ] **Series temporales**: 3-5 trayectorias ejemplo mostrando velocidad, aceleraci√≥n, consumo

### 9.2 Gr√°ficos de Feature Engineering
- [ ] **Bar plot**: Feature importance de Random Forest
- [ ] **Bar plot**: Coeficientes de Lasso/Ridge (top 10 features)
- [ ] **Violin plot**: Distribuci√≥n de features clave por categor√≠a de eficiencia

### 9.3 Gr√°ficos de Performance de Modelos
- [ ] **Bar chart**: Comparaci√≥n de RMSE entre todos los modelos (incluir baseline dummy)
- [ ] **Bar chart**: Comparaci√≥n de R¬≤ entre todos los modelos (baseline tendr√° R¬≤‚âà0)
- [ ] **Line chart**: Mejora relativa (%) vs baseline para cada modelo
- [ ] **Scatter plot**: Predicciones vs Valores Reales (para mejor modelo)
- [ ] **Scatter plot**: Comparaci√≥n baseline vs mejor modelo (lado a lado)
- [ ] **Residual plot**: An√°lisis de residuos del mejor modelo
- [ ] **Error distribution**: Histograma de errores por modelo

### 9.4 Gr√°ficos de Deep Learning
- [ ] **Learning curves**: Loss train vs validation por √©poca (para NN, AE, VAE)
- [ ] **Scatter plot 2D**: Espacio latente de VAE coloreado por tipo de veh√≠culo
- [ ] **Reconstruction examples**: Original vs Reconstruido para AE/VAE (3-5 ejemplos)
- [ ] **Bar chart**: Comparaci√≥n AE vs VAE vs Original features

### 9.5 Gr√°ficos de An√°lisis de Resultados
- [ ] **Box plot**: Error por tipo de veh√≠culo del mejor modelo
- [ ] **Box plot**: Error por tipo de ruta del mejor modelo
- [ ] **Heatmap**: Confusion matrix (si se hace clasificaci√≥n)
- [ ] **Curva ROC**: Multi-clase (si se hace clasificaci√≥n)
- [ ] **Mapas de calor**: Consumo vs velocidad vs temperatura (3D surface o heatmap 2D)

### 9.6 Gr√°ficos de Feature Importance y SHAP
- [ ] **SHAP summary plot**: Importancia global de features
- [ ] **SHAP dependence plot**: Para top 3 features m√°s importantes
- [ ] **SHAP force plot**: Explicaci√≥n de 2-3 predicciones individuales

---

## FASE 10: Hyperparameter Tuning

### 10.1 Tuning de Random Forest
- [ ] Grid/Random Search sobre:
  - `n_estimators`: [100, 200, 500]
  - `max_depth`: [10, 20, 30, None]
  - `min_samples_split`: [2, 5, 10]
  - `min_samples_leaf`: [1, 2, 4]
- [ ] Usar 5-fold Cross-Validation
- [ ] Documentar mejores hiperpar√°metros encontrados

### 10.2 Tuning de XGBoost/LightGBM
- [ ] Grid/Random Search sobre:
  - `n_estimators`: [100, 200, 500]
  - `learning_rate`: [0.01, 0.05, 0.1]
  - `max_depth`: [3, 5, 7, 10]
  - `subsample`: [0.7, 0.8, 0.9, 1.0]
  - `colsample_bytree`: [0.7, 0.8, 0.9, 1.0]
- [ ] Implementar Early Stopping
- [ ] Documentar mejores hiperpar√°metros

### 10.3 Tuning de Neural Networks
- [ ] B√∫squeda sobre:
  - Arquitectura: n√∫mero de capas [3, 4, 5]
  - Neuronas por capa: [32, 64, 128, 256]
  - Dropout rate: [0.1, 0.2, 0.3, 0.4]
  - Learning rate: [0.0001, 0.001, 0.01]
  - Batch size: [32, 64, 128]
- [ ] Usar Optuna, Keras Tuner o similar
- [ ] Documentar mejor arquitectura

### 10.4 Tuning de Autoencoders
- [ ] B√∫squeda sobre:
  - Dimensi√≥n del bottleneck: [8, 16, 32]
  - Arquitectura del encoder: diferentes profundidades
  - Learning rate: [0.0001, 0.001, 0.01]
  - Œ≤ para VAE: [0.5, 1.0, 2.0, 5.0]
- [ ] Evaluar basado en reconstruction loss
- [ ] Documentar mejor configuraci√≥n

---

## FASE 11: Evaluaci√≥n Final

### 11.1 Entrenamiento Final con Dataset Completo
- [ ] Entrenar mejor modelo en dataset completo (train + validation)
- [ ] Usar hiperpar√°metros √≥ptimos encontrados
- [ ] Monitorear tiempo de entrenamiento y recursos utilizados
- [ ] Guardar modelo entrenado final

### 11.2 Evaluaci√≥n en Test Set
- [ ] Cargar test set reservado (nunca usado hasta ahora)
- [ ] Generar predicciones con modelo final
- [ ] Calcular todas las m√©tricas (RMSE, MAE, R¬≤, MAPE)
- [ ] Comparar con resultados en validation set

### 11.3 An√°lisis de Errores Detallado
- [ ] Identificar top 10% peores predicciones
- [ ] Analizar caracter√≠sticas comunes de casos mal predichos
- [ ] Investigar posibles causas de errores sistem√°ticos
- [ ] Proponer mejoras futuras basadas en an√°lisis

### 11.4 Evaluaci√≥n por Subgrupos
- [ ] Calcular m√©tricas separadas por tipo de veh√≠culo
- [ ] Calcular m√©tricas separadas por tipo de ruta
- [ ] Identificar subgrupos donde el modelo funciona mejor/peor
- [ ] Analizar si hay sesgo en predicciones

---

## FASE 12: Interpretabilidad y Explicaci√≥n

### 12.1 Feature Importance Global
- [ ] Extraer feature importance del mejor modelo
- [ ] Generar ranking de top 15 features m√°s importantes
- [ ] Interpretar desde perspectiva f√≠sica/ingenieril cada feature importante
- [ ] Validar si features importantes tienen sentido con conocimiento del dominio

### 12.2 SHAP Values (SHapley Additive exPlanations)
- [ ] Calcular SHAP values para modelo final
- [ ] Generar SHAP summary plot (importancia global)
- [ ] Generar SHAP dependence plots para top 3 features
- [ ] Analizar interacciones entre features reveladas por SHAP
- [ ] Explicar 3-5 predicciones individuales con SHAP force plots

### 12.3 Partial Dependence Plots
- [ ] Generar PDP para top 5 features m√°s importantes
- [ ] Analizar relaci√≥n marginal entre cada feature y predicci√≥n
- [ ] Identificar umbrales o rangos cr√≠ticos en las variables

### 12.4 Interpretaci√≥n de Resultados
- [ ] Explicar qu√© factores m√°s influyen en el consumo energ√©tico
- [ ] Comparar diferencias entre veh√≠culos el√©ctricos, h√≠bridos y combusti√≥n
- [ ] Analizar impacto de condiciones ambientales (temperatura)
- [ ] Interpretar efecto del estilo de conducci√≥n (agresivo vs suave)

---

## FASE 13: Extensiones y An√°lisis Avanzado

### 13.1 An√°lisis Comparativo El√©ctricos vs H√≠bridos vs Combusti√≥n
- [ ] Entrenar modelos separados por tipo de veh√≠culo
- [ ] Comparar features importantes en cada tipo
- [ ] Analizar si factores de eficiencia difieren entre tipos
- [ ] Cuantificar diferencias promedio en consumo

### 13.2 Mapas de Calor de Eficiencia
- [ ] Crear heatmap 2D: Consumo vs Velocidad vs Temperatura
- [ ] Identificar "zona √≥ptima" de operaci√≥n para cada tipo de veh√≠culo
- [ ] Visualizar c√≥mo temperatura afecta eficiencia energ√©tica
- [ ] Crear curvas de eficiencia por rango de velocidad

### 13.3 An√°lisis de Impacto de Variables Externas
- [ ] Cuantificar impacto de temperatura en consumo (regresi√≥n parcial)
- [ ] Analizar efecto de potencia auxiliar (AC/calefacci√≥n)
- [ ] Evaluar diferencias entre tipos de ruta (urbano vs autopista)
- [ ] Estimar potencial de ahorro energ√©tico bajo condiciones √≥ptimas

### 13.4 Detecci√≥n de Anomal√≠as con Autoencoders
- [ ] Usar reconstruction error de AE/VAE como score de anomal√≠a
- [ ] Definir threshold para anomal√≠as (percentil 95 de reconstruction error)
- [ ] Identificar trayectos an√≥malos en test set
- [ ] Analizar caracter√≠sticas de trayectos an√≥malos
- [ ] Visualizar ejemplos de trayectos normales vs an√≥malos

### 13.5 Escenarios de Optimizaci√≥n
- [ ] Simular escenarios: ¬øQu√© pasa si reducimos velocidad promedio en 10%?
- [ ] Estimar ahorro energ√©tico de conducci√≥n m√°s suave
- [ ] Calcular impacto de eliminar uso de AC en d√≠as templados
- [ ] Proponer recomendaciones concretas para mejorar eficiencia

---

## FASE 14: Documentaci√≥n del Informe

### 14.1 Estructura del Informe
- [ ] **Resumen ejecutivo** (1 p√°gina): Problema, enfoque, resultados clave
- [ ] **Introducci√≥n**: Contexto, motivaci√≥n, objetivos
- [ ] **Dataset**: Descripci√≥n, fuente, caracter√≠sticas
- [ ] **An√°lisis exploratorio**: Insights principales con visualizaciones
- [ ] **Preprocesamiento**: Limpieza, curaci√≥n, decisiones tomadas
- [ ] **Feature Engineering**: Features creadas, selecci√≥n, justificaci√≥n
- [ ] **Metodolog√≠a**: Modelos probados, arquitecturas, hiperpar√°metros
- [ ] **Resultados**: Comparaci√≥n de modelos, m√©tricas, visualizaciones
- [ ] **An√°lisis de resultados**: Interpretaci√≥n, SHAP, feature importance
- [ ] **Discusi√≥n**: Limitaciones, sesgos, mejoras futuras
- [ ] **Conclusiones**: Hallazgos clave, respuesta a objetivos
- [ ] **Referencias**: Papers, documentaci√≥n, recursos utilizados

### 14.2 Secciones Cr√≠ticas del Informe

#### Tabla de Comparaci√≥n de Modelos
| Modelo | RMSE | MAE | R¬≤ | Tiempo Train | Complejidad |
|--------|------|-----|----|--------------| ------------|
| **Baseline (Media)** | ... | ... | 0.00 | <1s | M√≠nima |
| **Baseline (Por Grupo)** | ... | ... | ... | <1s | M√≠nima |
| Linear Regression | ... | ... | ... | ... | Baja |
| Random Forest | ... | ... | ... | ... | Media |
| XGBoost | ... | ... | ... | ... | Media-Alta |
| Neural Network | ... | ... | ... | ... | Alta |
| NN + AE features | ... | ... | ... | ... | Alta |
| NN + VAE features | ... | ... | ... | ... | Alta |

#### Resultados Clave a Reportar
- [ ] **M√©tricas del baseline** (media y por grupo) como referencia m√≠nima
- [ ] Modelo con mejor performance (RMSE en test)
- [ ] Top 5 features m√°s importantes
- [ ] Error promedio por tipo de veh√≠culo
- [ ] **Mejora porcentual respecto a baseline** (ej: 45% reducci√≥n en RMSE)
- [ ] Tiempo de inferencia del modelo final

### 14.3 Checklist de Calidad del Informe
- [ ] Todas las figuras tienen t√≠tulo, ejes etiquetados y leyenda
- [ ] Todas las tablas tienen caption descriptivo
- [ ] C√≥digo est√° documentado y reproducible
- [ ] Decisiones metodol√≥gicas est√°n justificadas
- [ ] Resultados num√©ricos tienen precisi√≥n apropiada (2-3 decimales)
- [ ] Se discuten limitaciones y sesgos del estudio
- [ ] Se proponen trabajos futuros
- [ ] Referencias est√°n formateadas correctamente
- [ ] Informe tiene narrativa coherente (no solo listado de gr√°ficos)

---

## FASE 15: Aspectos T√©cnicos y Reproducibilidad

### 15.1 Organizaci√≥n del C√≥digo
- [ ] Estructura de carpetas clara:
  ```
  TP_Final/
  ‚îú‚îÄ‚îÄ data/
  ‚îÇ   ‚îú‚îÄ‚îÄ raw/
  ‚îÇ   ‚îú‚îÄ‚îÄ processed/
  ‚îÇ   ‚îî‚îÄ‚îÄ splits/
  ‚îú‚îÄ‚îÄ notebooks/
  ‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb
  ‚îÇ   ‚îú‚îÄ‚îÄ 02_Preprocessing.ipynb
  ‚îÇ   ‚îú‚îÄ‚îÄ 03_Feature_Engineering.ipynb
  ‚îÇ   ‚îú‚îÄ‚îÄ 04_Modeling_Classical.ipynb
  ‚îÇ   ‚îú‚îÄ‚îÄ 05_Modeling_DL.ipynb
  ‚îÇ   ‚îú‚îÄ‚îÄ 06_Evaluation.ipynb
  ‚îÇ   ‚îî‚îÄ‚îÄ 07_Analysis.ipynb
  ‚îú‚îÄ‚îÄ src/
  ‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py
  ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py
  ‚îÇ   ‚îú‚îÄ‚îÄ models.py
  ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
  ‚îÇ   ‚îî‚îÄ‚îÄ visualization.py
  ‚îú‚îÄ‚îÄ models/
  ‚îÇ   ‚îî‚îÄ‚îÄ saved_models/
  ‚îú‚îÄ‚îÄ results/
  ‚îÇ   ‚îú‚îÄ‚îÄ figures/
  ‚îÇ   ‚îî‚îÄ‚îÄ metrics/
  ‚îú‚îÄ‚îÄ requirements.txt
  ‚îî‚îÄ‚îÄ README.md
  ```

### 15.2 Control de Versiones y Reproducibilidad
- [ ] Usar Git para control de versiones
- [ ] Fijar random seeds (42) en todos los experimentos
- [ ] Documentar versiones de librer√≠as en `requirements.txt`
- [ ] Guardar configuraciones de modelos en archivos JSON
- [ ] Documentar hardware utilizado (CPU/GPU)

### 15.3 Guardado de Artefactos
- [ ] Guardar scalers entrenados (pickle/joblib)
- [ ] Guardar modelos finales (pickle/h5/pt)
- [ ] Guardar splits de datos (√≠ndices)
- [ ] Guardar m√©tricas en CSV para referencia
- [ ] Guardar todas las figuras en alta resoluci√≥n (300 DPI)

---

## Checklist Final de Entrega

### Entregables Requeridos
- [ ] **Informe en PDF** (15-25 p√°ginas)
- [ ] **C√≥digo fuente** (notebooks + scripts .py)
- [ ] **README.md** con instrucciones de reproducci√≥n
- [ ] **requirements.txt** o environment.yml
- [ ] **Presentaci√≥n** (slides, 10-15 minutos)
- [ ] **Modelos entrenados** (si el tama√±o lo permite)

### Criterios de Evaluaci√≥n a Cubrir
- [ ] Calidad del an√°lisis exploratorio ‚úì
- [ ] Preprocesamiento y limpieza adecuados ‚úì
- [ ] Feature engineering creativo y justificado ‚úì
- [ ] Variedad de modelos comparados (cl√°sicos + DL) ‚úì
- [ ] Evaluaci√≥n rigurosa con m√©tricas apropiadas ‚úì
- [ ] Interpretabilidad y explicaci√≥n de resultados ‚úì
- [ ] Visualizaciones claras y profesionales ‚úì
- [ ] Calidad de escritura del informe ‚úì
- [ ] Reproducibilidad del trabajo ‚úì
- [ ] Insights de ingenier√≠a valiosos ‚úì

---

## üìÖ Cronograma Sugerido (3 semanas)

Nota: El cronograma se comprime a 3 semanas priorizando iteraciones r√°pidas y muestras de desarrollo (5k-10k) para validar decisiones antes de escalar al dataset completo.

### Semana 1 ‚Äî Exploraci√≥n, Curaci√≥n y Features Iniciales
- D√≠as 1-2: Carga de datos, EDA inicial (estad√≠sticas, missingness, outliers) y documentaci√≥n
- D√≠as 3-4: Limpieza y curaci√≥n (imputaci√≥n, tratamiento de outliers, coherencia de unidades)
- D√≠as 5-7: Feature engineering inicial y agregaci√≥n por `trip_id` (features clave para modelos r√°pidos)

### Semana 2 ‚Äî Modelado R√°pido y Tuning (desarrollo con muestra)
- D√≠as 1-2: Baselines y modelos simples (dummy mean/median, linear, ridge/lasso). Evaluaci√≥n sobre dev sample
- D√≠as 3-4: Modelos tree-based (Random Forest, XGBoost/LightGBM) y b√∫squeda de hiperpar√°metros b√°sica (Random Search)
- D√≠as 5-7: Primeras NN y/o AE/VAE en muestra peque√±a; comparar representaciones y rendimiento downstream

### Semana 3 ‚Äî Entrenamiento Final, Evaluaci√≥n y Documentaci√≥n
- D√≠as 1-2: Escalado a dataset grande (train+val) para el mejor modelo; entrenamiento final con hiperpar√°metros √≥ptimos
- D√≠as 3: Evaluaci√≥n final en test reservado, m√©tricas y an√°lisis por subgrupos (tipo veh√≠culo, tipo ruta)
- D√≠as 4-5: Interpretabilidad (SHAP, PDP) y an√°lisis de errores; generar visualizaciones clave
- D√≠as 6-7: Redacci√≥n del informe ejecutivo, preparar slides y empaquetar artefactos reproducibles

---

## M√©tricas de √âxito del Proyecto

### M√©tricas Cuantitativas
- [ ] **Superar baseline dummy** (predicci√≥n por media/grupo) significativamente
- [ ] R¬≤ > 0.80 en test set (excelente)
- [ ] RMSE < 15% del promedio de consumo
- [ ] MAPE < 10%
- [ ] **Mejora de al menos 40-50% en RMSE vs baseline dummy**
- [ ] Mejora de al menos 20-30% vs baseline de regresi√≥n lineal

### M√©tricas Cualitativas
- [ ] Insights accionables para mejorar eficiencia energ√©tica
- [ ] Interpretaci√≥n f√≠sica coherente de features importantes
- [ ] Visualizaciones que comunican claramente los hallazgos
- [ ] Informe bien estructurado y profesional

---

## Tips para un Informe Excelente

1. **Narrativa coherente**: El informe debe contar una historia, no ser solo una colecci√≥n de gr√°ficos
2. **Justificar decisiones**: Explicar el "por qu√©" de cada decisi√≥n metodol√≥gica
3. **Balance t√©cnico**: Suficiente detalle t√©cnico pero accesible
4. **Visualizaciones**: Menos es m√°s - cada gr√°fico debe aportar informaci√≥n valiosa
5. **Interpretaci√≥n**: No solo reportar n√∫meros, interpretarlos en contexto
6. **Limitaciones**: Discutir honestamente limitaciones y sesgos
7. **Reproducibilidad**: C√≥digo limpio, documentado y reproducible
8. **Originalidad**: M√°s all√° de lo pedido, aportar an√°lisis creativos

---

## Recursos Recomendados

### Librer√≠as Python
- **Data**: pandas, numpy
- **Visualizaci√≥n**: matplotlib, seaborn, plotly
- **ML Cl√°sico**: scikit-learn, xgboost, lightgbm, catboost
- **DL**: tensorflow/keras o pytorch
- **Interpretabilidad**: shap, lime, eli5
- **Tuning**: optuna, scikit-optimize
- **Utils**: joblib, pickle, tqdm

### Papers y Referencias
- Vehicle Energy Dataset original paper (DOE)
- Papers sobre predicci√≥n de consumo energ√©tico en veh√≠culos
- Documentaci√≥n de SHAP y t√©cnicas de interpretabilidad
- Tutoriales de autoencoders y VAEs